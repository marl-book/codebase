# @package _global_
env:
  parallel_envs: 8
  dummy_vecenv: true

algorithm:
  _target_: ac.train.main
  name: "ac"
  model:
    _target_: ac.model.Policy
    actor:
      layers:
        - 64
        - 64
      parameter_sharing: False # True/False/List[int] (seps_indices)
    critic:
      centralised: False
      layers:
        - 64
        - 64
      parameter_sharing: False # True/False/List[int] (seps_indices)

    device : "cpu"  # a pytorch device ("cpu" or "cuda")

  optimizer:
    _target_: torch.optim.Adam
    lr: 3.e-4
    eps: 0.00001

  grad_clip: False

  n_steps: 10
  gamma: 0.99
  entropy_coef: 0.01
  value_loss_coef: 0.5
  use_proper_termination: False
  standarize_returns: False

  target_update_interval_or_tau: 200
